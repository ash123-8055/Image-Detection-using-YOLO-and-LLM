{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = r\" \" # Root directory of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(r'') #Load the model of the best pt file\n",
    "\n",
    "results = model(r'') #Load the test image file\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy.cpu().numpy()  \n",
    "    scores = result.boxes.conf.cpu().numpy() \n",
    "    classes = result.boxes.cls.cpu().numpy() \n",
    "    \n",
    "    class_names = result.names\n",
    "\n",
    "    with open('output_predictions.txt', 'w') as f:\n",
    "        for i in range(len(boxes)):\n",
    "            class_id = int(classes[i])\n",
    "            class_name = class_names[class_id]\n",
    "            score = scores[i]\n",
    "            x1, y1, x2, y2 = boxes[i]\n",
    "            f.write(f'{class_id} {class_name} {score:.4f} {x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f}\\n')\n",
    "\n",
    "print(\"Predictions saved to output_predictions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Ollama API endpoint\n",
    "OLLAMA_ENDPOINT = \" \" #Ollama API endpoint\n",
    "\n",
    "# Read YOLO detection results\n",
    "with open(\"output_predictions.txt\", \"r\") as file:\n",
    "    yolo_results = file.readlines()\n",
    "\n",
    "# Format the YOLO results properly\n",
    "formatted_results = []\n",
    "for line in yolo_results:\n",
    "    parts = line.strip().split()\n",
    "    if len(parts) == 7:\n",
    "        formatted_results.append(f\"Detected {parts[1]} with {float(parts[2])*100:.1f}% confidence at coordinates ({parts[3]}, {parts[4]}, {parts[5]}, {parts[6]})\")\n",
    "\n",
    "# Read the prompt template\n",
    "with open(\"prompt_template.txt\", \"r\") as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "# Replace the placeholder with formatted results\n",
    "prompt = prompt_template.replace(\"%DETECTIONS%\", chr(10).join(formatted_results))\n",
    "\n",
    "# Request parameters\n",
    "data = {\n",
    "    \"model\": \"imagedet2\",\n",
    "    \"prompt\": prompt,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "# Make the API request\n",
    "response = requests.post(OLLAMA_ENDPOINT, json=data)\n",
    "response_json = response.json()\n",
    "print(\"\\nImage Analysis:\")\n",
    "print(response_json['response'])\n",
    "\n",
    "# Save the interpretation to a file\n",
    "with open(\"interpretation_results.txt\", \"w\") as f:\n",
    "    f.write(response_json['response'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
